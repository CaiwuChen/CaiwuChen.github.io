<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>TSDF Visualization and Robotic Arm Gripping System Project</title>
</head>
<body>

<h1>TSDF Visualization and Robotic Arm Gripping System Project</h1>
<p>The collection of Columbia COMS 4733 Computational Aspects of Robotics homework project.</p>
<img src="imgs/ur5.webp" alt="Project Image" style="max-width: 100%; height: auto;">
<p>Importance: 1</p>
<p>Category: work</p>

<p>In this page, I will go through what we did during the semester briefly.</p>
<p>Using Multi-view TSDF Algorithm to generate ply and visualize object point cloud in MeshLab given RGB-D image and camera pose file:</p>

<div class="row">
    <div class="col-sm mt-3 mt-md-0">
        <img src="imgs/Wall-E.png" alt="TSDF Image" class="img-fluid rounded z-depth-1">
    </div>
</div>
<p class="caption">This image records the mesh and point cloud of Wall-E in MeshLab.</p>

<p>In the following projects, we have learned to use the U-net to segment and detect the objects in the bins, and used ICP for pose estimation, and plans paths around obstacles using RRT.</p>

<div class="row justify-content-sm-center">
    <div class="col-sm-6 mt-3 mt-md-0">
        <img src="imgs/HW3-extra.png" alt="HW3 Image" class="img-fluid rounded z-depth-1">
    </div>
    <div class="col-sm-6 mt-3 mt-md-0">
        <img src="imgs/HW4.png" alt="HW4 Image" class="img-fluid rounded z-depth-1">
    </div>
</div>
<p class="caption">The left image records robot arm grasp object by segmentation and follow path generated by RRT. The right image demonstrates the Affordance Model.</p>

<p>We also experimented with other robotics arm gripping methods, such as Visual Affordance Model and Action Regression Model.</p>
<p>(credit: COMS4733 @columbia. not open-sourced)</p>

</body>
</html>
