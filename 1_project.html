<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>TSDF Visualization and Robotic Arm Gripping System Project</title>
</head>
<body>

<h1>TSDF Visualization and Robotic Arm Gripping System Project</h1>
<p>The collection of Columbia COMS 4733 Computational Aspects of Robotics homework project.</p>

<p>On this page, I will go through what we did during that semester briefly.</p>
    
<p>Using Multi-view TSDF Algorithm to generate ply and visualize object point cloud in MeshLab given RGB-D image and camera pose file:</p>

<div class="row">
    <div class="col-sm mt-3 mt-md-0">
        <img src="imgs/Wall-E.png" alt="TSDF Image" class="TSDF image" width="400">
    </div>
</div>
<p class="caption">This image records the mesh and point cloud of Wall-E in MeshLab.</p>

<p>In the following projects, we have learned to use the U-net to segment and detect the objects in the bins, and used ICP for pose estimation, and plans paths around obstacles using RRT.</p>

<div class="container">
    <div class="row justify-content-center">
        <div class="col-6 mt-3">
            <img src="imgs/HW3-extra.png" alt="HW3 Image" class="HW3 img-fluid" width="400">
        </div>
        <div class="col-6 mt-3">
            <img src="imgs/HW4.png" alt="HW4 Image" class="HW4 img-fluid" width="400">
        </div>
    </div>
</div>
<p class="caption">The upper image records the robot arm grasping objects by segmentation and follows the path generated by RRT. The bottom image demonstrates the Affordance Model.</p>

<p>We also experimented with other robotics arm gripping methods, such as the Visual Affordance Model and Action Regression Model.</p>
<p>(credit: COMS4733 @columbia. not open-sourced)</p>

</body>
</html>
